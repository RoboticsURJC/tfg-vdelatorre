{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1a: 2 beacon, 16 locations, Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the scores with mean and standard deviation for model\n",
    "# comparison\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def display_scores(scores):\n",
    "    count = 0\n",
    "    avg =[]\n",
    "    for score in scores:\n",
    "        count = count + 1\n",
    "        avg.append(score)\n",
    "        #print(f\"CV - {count} --> {score}\")\n",
    "    print(\"\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"Average accuracy --> {round(Average(avg),2)}\") \n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   B0  B1  Label\n",
      "0 -50 -34      8\n",
      "1 -54 -48     16\n",
      "2 -47 -46     15\n",
      "3 -50 -33      8\n",
      "4 -60 -36      2\n",
      "   B0  B1  Label\n",
      "0 -59 -36      1\n",
      "1 -59 -38      1\n",
      "2 -54 -37      1\n",
      "3 -60 -39      1\n",
      "4 -57 -38      1\n"
     ]
    }
   ],
   "source": [
    "# Load training set\n",
    "src = \"/home/victor/Escritorio/tfg/old/\"\n",
    "#train.csv\n",
    "f_name = \"/home/victor/Escritorio/tfg/old/salida.csv\"\n",
    "train = pd.read_csv(f_name, header = 0)\n",
    "print(train.head())\n",
    "\n",
    "# Load test set\n",
    "src1 = \"/home/victor/Escritorio/tfg/old/\"\n",
    "\n",
    "#test.csv\n",
    "f_name_1 = src1 + \"test_dos_apes_new.csv\"\n",
    "test = pd.read_csv(f_name_1, header = 0)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out feature variables and target variable, training set\n",
    "X_train = train.drop(['Label'], axis=1)\n",
    "y_train = train[\"Label\"]\n",
    "# Separate out feature variables and target variable, test set\n",
    "X_test = test.drop(['Label'], axis=1)\n",
    "y_test = test[\"Label\"]\n",
    "#X_test.head(10) Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1936\n",
      "Size of test set: 320\n"
     ]
    }
   ],
   "source": [
    "#Debug, size of training and test set\n",
    "print(f\"Size of training set: {len(X_train.index)}\")\n",
    "print(f\"Size of test set: {len(X_test.index)}\")\n",
    "#len(DataFrame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best C parameter --> 0.01\n",
      "\n",
      "-------------------------------------\n",
      "Accuracy --> 0.28125\n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Average accuracy --> 0.85\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[0.01], 'kernel':['linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid,refit = True, verbose= 1, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "grid.best_params_\n",
    "# Load bests C from best fit\n",
    "Cbest = grid.best_params_['C']\n",
    "# SVM with linear kernel and and best fit parameters\n",
    "print(f\"Best C parameter --> {Cbest}\")\n",
    "\n",
    "# Make predictions, Linear Kernel\n",
    "clf= SVC(kernel = 'linear', C = Cbest, decision_function_shape='ovr', gamma='scale').fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "#print(f\"Actual classes:     {np.asarray(y_test)}\")\n",
    "#print(f\"Predicted classes:  {clf_predictions}\")\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16' ]\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(\"\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Accuracy --> {a}\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter --> 1000\n",
      "Best gamma parameter --> 0.0001\n",
      "Accuracy --> 0.3125\n",
      "\n",
      "-------------------------------------\n",
      "Average accuracy --> 0.87\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[1000],'gamma':[0.0001], 'kernel':['rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Load bests C from best fit\n",
    "Cbest = grid.best_params_['C']\n",
    "gamma_best = grid.best_params_['gamma']\n",
    "\n",
    "print(f\"Best C parameter --> {Cbest}\")\n",
    "print(f\"Best gamma parameter --> {gamma_best}\")\n",
    "\n",
    "clf= SVC(kernel = 'rbf', C = Cbest, gamma=gamma_best, decision_function_shape='ovr').fit(X_train, y_train)\n",
    "# Make predictions, RBF Kernel\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16' ]\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1b: 2 node, 16 locations, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth parameter --> 10\n",
      "Accuracy --> 0.28125\n",
      "\n",
      "-------------------------------------\n",
      "Average accuracy --> 0.89\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'criterion':['gini','entropy'],'max_depth':[10]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid,refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "max_best = grid.best_params_['max_depth']\n",
    "print(f\"Best max_depth parameter --> {max_best}\")\n",
    "\n",
    "clf= DecisionTreeClassifier(criterion='gini', max_depth=max_best).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16']\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1c: 2 node, 16 locations, RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth parameter --> 100\n",
      "Best max_feature parameter --> sqrt\n",
      "Best min_leaf parameter --> 5\n",
      "Best min_split parameter --> 5\n",
      "Best n_estimator parameter --> 50\n",
      "Accuracy --> 0.253125\n",
      "\n",
      "-------------------------------------\n",
      "Average accuracy --> 0.89\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'bootstrap': [True],'max_depth': [1,5,10,50,100],'max_features': ['sqrt'],'min_samples_leaf': [5,10,20],'min_samples_split': [2,5,10],'n_estimators': [1,5,10,20,50]}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid,refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "depth_best = grid.best_params_['max_depth']\n",
    "max_feature_best = grid.best_params_['max_features']\n",
    "min_leaf_best = grid.best_params_['min_samples_leaf']\n",
    "min_split_best = grid.best_params_['min_samples_split']\n",
    "n_estimator_best = grid.best_params_['n_estimators']\n",
    "\n",
    "print(f\"Best max_depth parameter --> {depth_best}\")\n",
    "print(f\"Best max_feature parameter --> {max_feature_best}\")\n",
    "print(f\"Best min_leaf parameter --> {min_leaf_best}\")\n",
    "print(f\"Best min_split parameter --> {min_split_best}\")\n",
    "print(f\"Best n_estimator parameter --> {n_estimator_best}\")\n",
    "\n",
    "clf= RandomForestClassifier(n_estimators = n_estimator_best,criterion='gini', max_depth = depth_best, max_features = max_feature_best, min_samples_leaf = min_leaf_best,min_samples_split = min_split_best).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16']\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
